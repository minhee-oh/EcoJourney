# backend/services/llm_service.py

import json
import logging
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

GEMINI_API_KEY = "AIzaSyAkTtjvEMESxHdFebJ5CQs5Nd_d0nnHWnU"

MODEL_NAME = "gemini-flash-latest"

try:
    import google.generativeai as genai
except ImportError:
    genai = None
    logger.error(
        "[llm_service] google-generativeai íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. "
        "venvì—ì„œ `pip install google-generativeai` ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”."
    )

if genai and GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    logger.info("[llm_service] Gemini API í‚¤ ì„¤ì • ì™„ë£Œ â†’ ì‹¤ì œ LLM í˜¸ì¶œ ì‚¬ìš©")
else:
    logger.warning(
        "[llm_service] Gemini ì„¤ì • ë¶ˆê°€ â†’ ì‹œë®¬ë ˆì´ì…˜ ì‘ë‹µë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤."
    )


# ----------------------------------------------------------------------
# í´ë°±: Gemini ì•ˆ ë  ë•Œ ì“°ëŠ” ì‹œë®¬ë ˆì´ì…˜ ì‘ë‹µ
# ----------------------------------------------------------------------
def _build_simulated_response(user_data: Dict[str, Any]) -> Dict[str, Any]:
    carbon_data: Dict[str, float] = user_data.get("category_carbon_data", {}) or {}
    total_carbon_kg: float = user_data.get("total_carbon_kg", 0.0)

    if carbon_data:
        max_category = max(carbon_data, key=carbon_data.get)
        max_carbon_kg = carbon_data[max_category]
    else:
        max_category = "ë¶„ì„ ë¶ˆê°€"
        max_carbon_kg = 0.0

    highlight_message = (
        f"ì´ë²ˆ ì£¼ì—ëŠ” **'{max_category}'** ì¹´í…Œê³ ë¦¬ì—ì„œ íƒ„ì†Œ ë°°ì¶œì´ ê°€ì¥ ë§ì•˜ì–´ìš”. "
        f"ì´ ì˜ì—­ì—ì„œë§Œ ì•½ {max_carbon_kg:.2f}kg COâ‚‚eê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. "
    )

    return {
        "title": f"ì‚¬ìš©ì ë‹˜ì˜ ì£¼ê°„ íƒ„ì†Œ ë¼ì´í”„ ì§„ë‹¨ ê²°ê³¼ (ì´ {total_carbon_kg:.2f}kg COâ‚‚e)",
        "summary": (
            f"ì´ë²ˆ ì£¼ ì‚¬ìš©ì ë‹˜ì€ ì—¬ëŸ¬ ì˜ì—­ì—ì„œ í™˜ê²½ì„ ì‹ ê²½ ì“°ì…¨ì§€ë§Œ, "
            f"íŠ¹íˆ {max_category} ì¹´í…Œê³ ë¦¬ì—ì„œ ë°°ì¶œëŸ‰ì´ ë‘ë“œëŸ¬ì¡Œì–´ìš”. "
            "ê·¸ë˜ë„ ì´ë¯¸ ë°ì´í„°ë¥¼ ê¸°ë¡í•˜ê³  ëŒì•„ë³´ëŠ” ê²ƒë§Œìœ¼ë¡œ í° ì²«ê±¸ìŒì„ ë‚´ë””ë”˜ ìƒíƒœì˜ˆìš”. ğŸ’ª"
        ),
        "highlight": highlight_message,
        "focus_area": f"ë‹¤ìŒ ì£¼ì— í•¨ê»˜ ì§‘ì¤‘í•´ì„œ ì¡°ì •í•´ ë³´ë©´ ì¢‹ì„ ì˜ì—­: {max_category}",
        "recommendations": [
            {
                "action": f"{max_category} í™œë™ 15% ê°ì¶• ì±Œë¦°ì§€",
                "detail": (
                    f"ê°€ì¥ ë§ì€ íƒ„ì†Œë¥¼ ë°°ì¶œí•œ {max_category} ê´€ë ¨ í–‰ë™ ì¤‘, "
                    "ì¼ì£¼ì¼ì— 2~3íšŒë§Œ ëŒ€ì²´ í–‰ë™(ëŒ€ì¤‘êµí†µ, ê±·ê¸°, ì±„ì‹ ì„ íƒ ë“±)ìœ¼ë¡œ ë°”ê¿”ë³´ì„¸ìš”. "
                    "í•œ ë²ˆì— ì™„ë²½íˆ ë°”ê¾¸ê¸°ë³´ë‹¤ëŠ” 'ì¡°ê¸ˆ ì¤„ì´ëŠ” ê²½í—˜'ì„ ìŒ“ëŠ” ê²Œ ì¤‘ìš”í•´ìš”."
                ),
                "impact": f"ìµœëŒ€ ì•½ {max_carbon_kg * 0.15:.2f}kg COâ‚‚e ê°ì¶• ê°€ëŠ¥",
            },
            {
                "action": "ì£¼ìš” ì†Œë¹„ ì „ '30ì´ˆ ë©ˆì¶¤' ë£¨í‹´",
                "detail": (
                    f"'{max_category}'ì²˜ëŸ¼ í° ì†Œë¹„ë¥¼ í•˜ê¸° ì „, "
                    "'ì´ ì„ íƒì´ ë‚´ íƒ„ì†Œ ë°œìêµ­ê³¼ ì§€ê°‘ì— ì–´ë–¤ ì˜í–¥ì„ ì¤„ê¹Œ?'ë¥¼ 30ì´ˆë§Œ ë– ì˜¬ë ¤ë³´ì„¸ìš”. "
                    "ì´ ì§§ì€ ë©ˆì¶¤ë§Œìœ¼ë¡œë„ ì¶©ë™ì ì¸ ì†Œë¹„ì™€ ë¶ˆí•„ìš”í•œ ë°°ì¶œì„ ì¤„ì´ëŠ” íš¨ê³¼ê°€ í½ë‹ˆë‹¤."
                ),
                "impact": "ì¶©ë™ ì†Œë¹„ ê°ì†Œ ë° ì¥ê¸°ì ì¸ íƒ„ì†Œ ë°°ì¶œ ì˜ˆë°© íš¨ê³¼",
            },
        ],
        "closing_message": (
            "ì‚¬ìš©ì ë‹˜ì€ ì´ë¯¸ 'ê¸°ë¡í•˜ê³  ëŒì•„ë³´ëŠ” ì‚¬ëŒ'ì´ë¼ëŠ” ì ì—ì„œ í° ì¶œë°œì„ ì„ í†µê³¼í•˜ì…¨ì–´ìš”. "
            "ë‹¤ìŒ ì£¼ì—ëŠ” ìœ„ ì œì•ˆë“¤ ì¤‘ í•˜ë‚˜ë§Œ ì‹¤ì²œí•´ë„ ì¶©ë¶„í•©ë‹ˆë‹¤. "
            "í™˜ê²½ ì½”ì¹˜ì¸ ì œê°€ ê³„ì† ì˜†ì—ì„œ ì‘ì›í• ê²Œìš”! ğŸ˜Š"
        ),
    }


# ----------------------------------------------------------------------
# ì‹¤ì œ Gemini í˜¸ì¶œ í•¨ìˆ˜
# ----------------------------------------------------------------------
def call_llm_api(prompt: str, user_data: Dict[str, Any]) -> str:
    if not genai or not GEMINI_API_KEY:
        logger.warning("[llm_service] Gemini ì„¤ì • ë¶ˆê°€ â†’ ì‹œë®¬ë ˆì´ì…˜ ì‘ë‹µ ì‚¬ìš©")
        simulated = _build_simulated_response(user_data)
        return json.dumps(simulated, ensure_ascii=False, indent=4)

    try:
        logger.info("[llm_service] ì‹¤ì œ Gemini 1.5 Flash í˜¸ì¶œ ì¤‘...")
        model = genai.GenerativeModel(MODEL_NAME)
        response = model.generate_content(prompt)
        raw_text = (response.text or "").strip()

        # ```json ... ``` í˜•íƒœë¡œ ì˜¤ë©´ ì½”ë“œë¸”ë¡ ì œê±°
        if raw_text.startswith("```"):
            lines = raw_text.splitlines()
            if len(lines) >= 2 and lines[0].startswith("```") and lines[-1].startswith("```"):
                lines = lines[1:-1]
            if lines and lines[0].strip().lower() == "json":
                lines = lines[1:]
            raw_text = "\n".join(lines).strip()

        parsed = json.loads(raw_text)  # LLMì´ ë°˜í™˜í•œ JSON íŒŒì‹±
        return json.dumps(parsed, ensure_ascii=False, indent=4)

    except Exception as e:
        logger.error(f"[llm_service] Gemini í˜¸ì¶œ / JSON íŒŒì‹± ì‹¤íŒ¨ â†’ ì‹œë®¬ë ˆì´ì…˜ ì‘ë‹µ ì‚¬ìš©: {e}")
        simulated = _build_simulated_response(user_data)
        return json.dumps(simulated, ensure_ascii=False, indent=4)

def get_coaching_feedback(user_data: Dict[str, Any]) -> str:
    from backend.config.coaching_rules import COACHING_KNOWLEDGE_RULE

    prompt = create_coaching_prompt(user_data, COACHING_KNOWLEDGE_RULE)
    llm_response_json = call_llm_api(prompt, user_data)
    return llm_response_json
# ----------------------------------------------------------------------
# í”„ë¡¬í”„íŠ¸ ìƒì„±
# ----------------------------------------------------------------------
def create_coaching_prompt(user_data: Dict[str, Any], knowledge_rule: Dict[str, Any]) -> str:
    # 1) ì¹´í…Œê³ ë¦¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°: carbon / activity ë‘˜ ë‹¤ ëŒ€ì‘
    carbon_data = (
        user_data.get("category_carbon_data")
        or user_data.get("category_activity_data")
        or {}
    )

    # 2) ì´ ë°°ì¶œëŸ‰ ê³„ì‚°: ìš°ì„  total_carbon_kg, ì—†ìœ¼ë©´ carbon_data í•©
    total_carbon_kg = user_data.get("total_carbon_kg")
    if total_carbon_kg is None:
        # ìˆ«ìë¡œ ë“¤ì–´ì™”ë‹¤ê³  ê°€ì •í•˜ê³  í•©ì‚° (ì—†ìœ¼ë©´ 0)
        try:
            total_carbon_kg = float(sum(carbon_data.values())) if carbon_data else 0.0
        except Exception:
            total_carbon_kg = 0.0

    # 3) ì¹´í…Œê³ ë¦¬ ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„±
    if carbon_data:
        category_summary = "\n".join(
            [f"- {k}: {float(v):.2f} kg CO2e" for k, v in carbon_data.items()]
        )
    else:
        category_summary = "- ìƒì„¸ ì¹´í…Œê³ ë¦¬ ë°ì´í„° ì—†ìŒ"

    data_summary = (
        "## [ì‚¬ìš©ì ì£¼ê°„ í™œë™ ìš”ì•½ ë°ì´í„°]\n"
        f"1. ì£¼ê°„ ì´ íƒ„ì†Œ ë°°ì¶œëŸ‰: {total_carbon_kg:.2f} kg CO2e\n"
        "## [ìƒì„¸ ì¹´í…Œê³ ë¦¬ë³„ íƒ„ì†Œ ë°°ì¶œëŸ‰ ë‚´ì—­]\n"
        "(ì•„ë˜ ê°’ì€ ì´ë¯¸ 'kg CO2e' ë‹¨ìœ„ë¡œ í™˜ì‚°ëœ ê°’ì´ë©°, ë¶„ì„ì˜ í•µì‹¬ ê·¼ê±°ì…ë‹ˆë‹¤.)\n"
        f"{category_summary}\n"
    )

    system_instruction = knowledge_rule["system_instruction"]
    coaching_principles = "\n".join(
        [f"- {p}" for p in knowledge_rule.get("coaching_principles", [])]
    )
    json_schema = json.dumps(knowledge_rule["json_schema"], ensure_ascii=False, indent=2)

    prompt = f"""
{system_instruction}

[ë°ì´í„° ë¶„ì„ ì›ì¹™]
ì•„ë˜ ì›ì¹™ì„ ìµœëŒ€í•œ ì¶©ì‹¤íˆ ë”°ë¥´ì‹­ì‹œì˜¤:
{coaching_principles}

[ë¶„ì„ ëŒ€ìƒ ë°ì´í„°]
ì•„ë˜ëŠ” ì‚¬ìš©ìì˜ ì‹¤ì œ ì£¼ê°„ í™œë™ ë°ì´í„°ë¥¼ ì •ë¦¬í•œ ë‚´ìš©ì…ë‹ˆë‹¤.
ì´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ íŒ¨í„´ì„ ë¶„ì„í•˜ê³ , ì‹¤ì²œ ê°€ëŠ¥í•œ ì½”ì¹­ì„ ì œê³µí•˜ì‹­ì‹œì˜¤.

{data_summary}

[ì¶œë ¥ í˜•ì‹]
ë°˜ë“œì‹œ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¥´ëŠ” í•˜ë‚˜ì˜ JSON ê°ì²´ë§Œì„ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.
ì„¤ëª… ë¬¸ì¥ì´ë‚˜ ì½”ë“œë¸”ë¡ ê¸°í˜¸( ``` )ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
JSON ì´ì™¸ì˜ ì–´ë–¤ í…ìŠ¤íŠ¸ë„ ì¶œë ¥í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.

JSON ìŠ¤í‚¤ë§ˆ:
{json_schema}

[ì¶”ê°€ ì§€ì¹¨]
- í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•©ë‹ˆë‹¤.
- ë»”í•œ ì¡°ì–¸ì´ ì•„ë‹ˆë¼, ìœ„ ë°ì´í„°ì— ë§ëŠ” êµ¬ì²´ì ì¸ ë¶„ì„ê³¼ í–‰ë™ ì œì•ˆì„ ì œê³µí•©ë‹ˆë‹¤.
"""
    return prompt.strip()
