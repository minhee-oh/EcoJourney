# íŒŒì¼ ê²½ë¡œ: ecojourney/ai/llm_service.py
# íƒ„ì†Œ ë°°ì¶œëŸ‰ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ
# AI(Gemini)ë¥¼ í˜¸ì¶œí•´ ì½”ì¹­ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ê³ ,
# ì‹¤íŒ¨ ì‹œì—ë„ í•­ìƒ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëŒ€ì²´ ì‘ë‹µì„ ì œê³µí•˜ëŠ” ì„œë¹„ìŠ¤ ëª¨ë“ˆ
import json
import logging
import os
from typing import Dict, Any

from dotenv import load_dotenv

logger = logging.getLogger(__name__)

# -------------------------------
# 1) .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
# -------------------------------
load_dotenv(override=True) # í”„ë¡œì íŠ¸ ë£¨íŠ¸(OpenSourceProject/.env)ì—ì„œ ë¡œë“œ

# Gemini API ì„¤ì •
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")  # .envì—ì„œ í‚¤ ì½ê¸°
MODEL_NAME = "gemini-flash-latest"

# ğŸ” ë””ë²„ê·¸ìš©: í‚¤ ì•ë¶€ë¶„ë§Œ ì°ì–´ë³´ê¸° (Noneì¼ ë•Œë„ ì•ˆì „í•˜ê²Œ)
key_prefix = GEMINI_API_KEY[:8] if GEMINI_API_KEY else "NONE"
print(f"[DEBUG] llm_service loaded. GEMINI_API_KEY prefix: {key_prefix}")
logger.info(f"[llm_service] GEMINI_API_KEY prefix: {key_prefix}")

if not GEMINI_API_KEY:
    logger.error("[llm_service] âŒ GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
else:
    logger.info("[llm_service] ğŸ”‘ Gemini API Key ë¡œë“œ ì„±ê³µ")

# -------------------------------
# 2) Gemini SDK ë¡œë”©
# -------------------------------
try:
    import google.generativeai as genai
except ImportError:
    genai = None
    logger.error("[llm_service] google-generativeai íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. pip install í•„ìš”.")

# -------------------------------
# 3) Gemini ì´ˆê¸°í™”
# -------------------------------
if genai and GEMINI_API_KEY:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        logger.info("[llm_service] Gemini API ì„¤ì • ì™„ë£Œ")
    except Exception as e:
        logger.error(f"[llm_service] Gemini ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
else:
    logger.warning("[llm_service] Gemini ì‚¬ìš© ë¶ˆê°€ â†’ ì‹œë®¬ë ˆì´ì…˜ ì‘ë‹µ ì‚¬ìš©")


# ======================================================================
# 1) Gemini ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  í´ë°±(ê¸°ë³¸ ì‘ë‹µ)
# ======================================================================
def _build_simulated_response(user_data: Dict[str, Any]) -> Dict[str, Any]:
    """Gemini í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í…œí”Œë¦¿ ê¸°ë°˜ JSON ì‘ë‹µ ìƒì„±"""

    def _safe_float(value: Any) -> float:
        try:
            return float(value)
        except (TypeError, ValueError):
            return 0.0

    # ì›ë³¸ ë°ì´í„°
    raw_carbon_data = user_data.get("category_carbon_data", {}) or {}

    # ëª¨ë“  ê°’ì„ floatìœ¼ë¡œ í•œ ë²ˆ ì •ë¦¬
    carbon_data = {
        k: _safe_float(v) for k, v in raw_carbon_data.items()
    }

    total_carbon_kg = _safe_float(user_data.get("total_carbon_kg", 0.0))

    # ë°ì´í„° ìˆëŠ”ì§€ ì²´í¬ (0ë³´ë‹¤ í° ê°’ì´ í•˜ë‚˜ë¼ë„ ìˆëŠ”ì§€)
    has_data = bool(carbon_data) and any(v > 0 for v in carbon_data.values())

    # ë°ì´í„°ê°€ ìˆì„ ë•Œ
    if has_data:
        max_category = max(carbon_data, key=carbon_data.get)
        max_value = carbon_data[max_category]
        total = sum(carbon_data.values()) or 1.0
        max_ratio = (max_value / total) * 100

        # ë‘ ë²ˆì§¸ ì¹´í…Œê³ ë¦¬
        sorted_items = sorted(carbon_data.items(), key=lambda x: x[1], reverse=True)
        second_category, second_value = (None, 0.0)
        if len(sorted_items) >= 2:
            second_category, second_value = sorted_items[1]

        # ì§€êµ¬ ìƒíƒœ ë ˆë²¨(ê°„ë‹¨ ê³„ì‚°)
        if total_carbon_kg <= 2:
            earth_level = "Level 1 - ì•„ì£¼ ìƒì¾Œí•´ìš” ğŸƒ"
        elif total_carbon_kg <= 5:
            earth_level = "Level 2 - ê½¤ ê´œì°®ì€ í•˜ë£¨ì˜ˆìš” ğŸ™‚"
        else:
            earth_level = "Level 3 - ì¡°ê¸ˆ ì§€ì¹œ í•˜ë£¨ì˜ˆìš” ğŸŒ"

        report_title = f"ì˜¤ëŠ˜ í•˜ë£¨ íƒ„ì†Œ ì§„ë‹¨ ê²°ê³¼ ({total_carbon_kg:.2f} kg CO2e)"

        today_result_screen = {
            "usage_summary_text": f"ì˜¤ëŠ˜ íƒ„ì†Œ ì‚¬ìš©ëŸ‰ì€ ì´ {total_carbon_kg:.2f} kg CO2eì˜ˆìš”.",
            "category_ratio_text": (
                f"{max_ratio:.0f}%ê°€ '{max_category}'ì—ì„œ ë°œìƒí–ˆê³ , "
                f"ë‹¤ìŒì€ '{second_category}'ì…ë‹ˆë‹¤." if second_category
                else f"ê±°ì˜ ëŒ€ë¶€ë¶„ì´ '{max_category}'ì—ì„œ ë°œìƒí–ˆì–´ìš”."
            ),
            "money_saving_text": "ì˜¤ëŠ˜ íŒ¨í„´ë§Œ ì¡°ì •í•´ë„ í•œ ë‹¬ ê¸°ì¤€ ìƒí™œë¹„ ì ˆê° ì—¬ì§€ê°€ ìˆì–´ìš”.",
            "earth_status_text": f"ì˜¤ëŠ˜ì˜ ì§€êµ¬ ìƒíƒœëŠ” {earth_level}",
        }

        final_summary = (
            f"ì˜¤ëŠ˜ ì´ ë°°ì¶œëŸ‰ì€ {total_carbon_kg:.2f} kg CO2e. "
            f"'{max_category}' ë¹„ì¤‘ì´ ê°€ì¥ ë†’ê³ , "
            f"'{second_category}'ê°€ ë’¤ë¥¼ ì‡ìŠµë‹ˆë‹¤." if second_category
            else f"ì˜¤ëŠ˜ì€ '{max_category}' í•œ ì˜ì—­ì— ì‚¬ìš©ëŸ‰ì´ ëª°ë¦° íŒ¨í„´ì´ì—ìš”."
        )

        category_chart_text = (
            f"ê·¸ë˜í”„ì—ì„œë„ '{max_category}'ì™€ '{second_category}'ê°€ ë‘ë“œëŸ¬ì§‘ë‹ˆë‹¤."
            if second_category else
            f"'{max_category}'ê°€ ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ë³´ë‹¤ ë†’ê²Œ ë‚˜íƒ€ë‚˜ìš”."
        )

        recommendations = [
            {
                "action": f"'{max_category}' ì‚¬ìš©ëŸ‰ 20% ì¤„ì´ê¸°",
                "detail": (
                    f"'{max_category}' ì‚¬ìš©ì´ ë†’ì•˜ë˜ ì´ìœ ë¥¼ ë– ì˜¬ë¦¬ê³ , "
                    "ê°€ì¥ ë°˜ë³µëœ í–‰ë™ 1ê°œë§Œ 20% ì¤„ì—¬ë³´ì„¸ìš”."
                ),
                "impact": f"{max_value * 0.2:.2f} kg CO2e ê°ì¶• ê°€ëŠ¥",
                "reason": f"'{max_category}'ê°€ ì˜¤ëŠ˜ ë°°ì¶œì˜ í•µì‹¬ ìš”ì¸ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
            },
            {
                "action": "ë¹„ìŠ·í•œ ìƒí™©ì„ ìœ„í•œ í”Œëœ B ë§Œë“¤ê¸°",
                "detail": (
                    "í–‰ë™ íŒ¨í„´ì„ ë§ì¶”ê±°ë‚˜ ì˜ˆì¸¡ì€ ì–´ë µê¸°ì— ê·¸ëƒ¥ ì•„ì˜ˆ ëŒ€ì•ˆ ìì²´ë¥¼ ì¶”ì²œí•˜ëŠ” ê±¸ë¡œ ê°€ì•¼í•©ë‹ˆë‹¤,"
                    "ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë»”í•˜ì§€ ì•Šì€ ëŒ€ì•ˆë“¤ì„ ì¶”ì²œí•˜ì„¸ìš”."
                ),
                "impact": "ë°˜ë³µë ìˆ˜ë¡ ê°ì¶• íš¨ê³¼ê°€ ëˆ„ì ë©ë‹ˆë‹¤.",
                "reason": "ì˜¤ëŠ˜ ë°ì´í„°ê°€ ë°˜ë³µ íŒ¨í„´ì˜ íŒíŠ¸ë¥¼ ì œê³µí•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
            },
            {
                "action": "ì‹¤ìƒí™œì—ì„œ í•  ìˆ˜ ìˆëŠ” í˜„ì‹¤ì ì¸ ëŒ€ì•ˆì„ ìƒê°í•´ì„œ ì¶”ì²œí•´ì£¼ê¸°",
                "detail": (
                    "ë»”í•œ ë‚´ìš©ì´ì—¬ë„ ë””í…Œì¼ì„ ì¶”ê°€í•´ì„œ ë” ì„¬ì„¸í•´ë³´ì´ê²Œ, "
                    "ìˆ˜ì¹˜ë‚˜ ê²°ê³¼ë¡ ì ì¸ ê²ƒë“¤ë¡œ ë”ìš±ë” ì˜ ë³´ì´ê²Œ í•´ì£¼ì„¸ìš”."
                ),
                "impact": "ì¹´í…Œê³ ë¦¬ë³„ ë°°ì¶œëŸ‰ì„ íŒŒì•…í•´ì„œ ëŒ€ì•ˆ ì¶”ì²œí•˜ê¸°, ë»”í•œ 'ì±„ì†Œë¥¼ ë“œì„¸ìš”.', 'ìŠ¹ìš©ì°¨ ëŒ€ì‹  ë²„ìŠ¤ë¥¼ ì´ìš©í•˜ì„¸ìš”', 'ì˜·ì„ ì˜¤ë˜ ì…ìœ¼ì„¸ìš”', 'ë¶„ë¦¬ìˆ˜ê±°ë¥¼ ì˜í•˜ì„¸ìš”', 'ë¬¼ì´ë‚˜ ì „ê¸°ë¥¼ ì•„ë¼ì„¸ìš”' ê¸ˆì§€",
                "reason": "ì‚¬ìš©ìê°€ í¥ë¯¸ë¥¼ ê°€ì§€ê¸° ìœ„í•´ì„œ, ê·¸ë¦¬ê³  ë‹¤ë¥¸ ì›¹ì‚¬ì´íŠ¸ë‚˜ ì •ë³´ì— ëŒ€í•œ ì°¨ë³„ì„±ì„ ë‘ê¸° ìœ„í•´ì„œ ì…ë‹ˆë‹¤.",
            },
        ]

        simulated = {
            "report_title": report_title,
            "today_result_screen": today_result_screen,
            "final_report_screen": {
                "total_summary_text": final_summary,
                "category_chart_text": category_chart_text,
                "focus_area": max_category,
                "recommendations": recommendations,
                "policy_recommendations": [],
                "closing_message": (
                    f"ì¶”ì²œ ì¤‘ í•œ ê°€ì§€ë§Œ ì‹¤í–‰í•´ë„ '{max_category}' ê°œì„ ì— í° ë„ì›€ì´ ë©ë‹ˆë‹¤."
                ),
            },
        }

    # ë°ì´í„° ì—†ì„ ë•Œ
    else:
        simulated = {
            "report_title": "ì˜¤ëŠ˜ì€ ê¸°ë¡ëœ íƒ„ì†Œ ë°ì´í„°ê°€ ë¶€ì¡±í•´ìš”.",
            "today_result_screen": {
                "usage_summary_text": "íƒ„ì†Œ ì‚¬ìš©ëŸ‰ ê¸°ë¡ì´ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤.",
                "category_ratio_text": "ì¹´í…Œê³ ë¦¬ ê¸°ë¡ì´ ì—†ìœ¼ë©´ ë¶„ì„ì´ ì–´ë µìŠµë‹ˆë‹¤.",
                "money_saving_text": "ê¸°ë¡ì„ ì‹œì‘í•˜ë©´ ì ˆê° ì§€ì ì„ ë” ì •í™•íˆ ì°¾ì„ ìˆ˜ ìˆì–´ìš”.",
                "earth_status_text": "ë‚´ì¼ë¶€í„° í•œ ì¹´í…Œê³ ë¦¬ë§Œ ê¸°ë¡í•´ë´ë„ ì˜ë¯¸ê°€ ìƒê²¨ìš”.",
            },
            "final_report_screen": {
                "total_summary_text": "ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ íŒ¨í„´ ë¶„ì„ì´ ì–´ë µìŠµë‹ˆë‹¤.",
                "category_chart_text": "ì°¨íŠ¸ë¥¼ ê·¸ë¦´ ìˆ˜ ìˆëŠ” ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.",
                "focus_area": "ê¸°ë¡ ì‹œì‘í•˜ê¸°",
                "recommendations": [
                    {
                        "action": "ë‚´ì¼ ì¹´í…Œê³ ë¦¬ í•˜ë‚˜ë§Œ ê¸°ë¡í•˜ê¸°",
                        "detail": "êµí†µÂ·ìŒì‹ ë“± í•œ ì˜ì—­ë§Œ ìˆ«ìë¡œ ê¸°ë¡í•´ë³´ì„¸ìš”.",
                        "impact": "ê¸°ë¡ì´ ìŒ“ì´ë©´ ì •í™•í•œ ê°ì¶• ì „ëµ ë„ì¶œ ê°€ëŠ¥",
                        "reason": "í˜„ì¬ëŠ” ë¶„ì„ ê°€ëŠ¥í•œ ì •ë³´ê°€ ì—†ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
                    }
                ],
                "policy_recommendations": [],
                "closing_message": "ë¶€ë‹´ ì—†ì´ ë‚´ì¼ í•œ ì¹´í…Œê³ ë¦¬ë§Œ ê¸°ë¡í•´ë´ìš”.",
            },
        }

    return simulated



# ======================================================================
# 2) Gemini í˜¸ì¶œ + JSON íŒŒì‹±
# ======================================================================
def call_llm_api(prompt: str, user_data: Dict[str, Any]) -> str:
    """Gemini í˜¸ì¶œ â†’ JSON íŒŒì‹± â†’ ì‹¤íŒ¨ ì‹œ í´ë°± JSON ë°˜í™˜"""
    if not genai or not GEMINI_API_KEY:
        simulated = _build_simulated_response(user_data)
        return json.dumps(simulated, ensure_ascii=False, indent=4)

    try:
        model = genai.GenerativeModel(MODEL_NAME)
        response = model.generate_content(prompt)
        raw_text = (response.text or "").strip()

        # ì½”ë“œë¸”ë¡(```) ì œê±°
        if raw_text.startswith("```"):
            lines = raw_text.splitlines()
            if len(lines) >= 2 and lines[0].startswith("```") and lines[-1].startswith("```"):
                lines = lines[1:-1]
            if lines and lines[0].strip().lower() == "json":
                lines = lines[1:]
            raw_text = "\n".join(lines).strip()

        # JSON íŒŒì‹±
        parsed = json.loads(raw_text)
        return json.dumps(parsed, ensure_ascii=False, indent=4)

    except Exception as e:
        logger.error("[llm_service] Gemini ì‹¤íŒ¨ â†’ í´ë°± ì‚¬ìš©: %s", e)
        simulated = _build_simulated_response(user_data)
        return json.dumps(simulated, ensure_ascii=False, indent=4)


# ======================================================================
# 3) ì™¸ë¶€ í˜¸ì¶œìš© ë©”ì¸ í•¨ìˆ˜
# ======================================================================
def get_coaching_feedback(user_data: Dict[str, Any]) -> str:
    """coaching_apiì—ì„œ í˜¸ì¶œí•˜ëŠ” LLM í”¼ë“œë°± ìƒì„± ì§„ì…ì """
    from ecojourney.config.coaching_rules import COACHING_KNOWLEDGE_RULE

    prompt = create_coaching_prompt(user_data, COACHING_KNOWLEDGE_RULE)
    return call_llm_api(prompt, user_data)


# ======================================================================
# 4) í”„ë¡¬í”„íŠ¸ ìƒì„±
# ======================================================================
def create_coaching_prompt(
    user_data: Dict[str, Any],
    knowledge_rule: Dict[str, Any],
) -> str:
    """ì˜¤ëŠ˜ í•˜ë£¨ ë°ì´í„° ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    carbon_data = (
        user_data.get("category_carbon_data")
        or user_data.get("category_activity_data")
        or {}
    )

    total_carbon_kg = user_data.get("total_carbon_kg")
    if total_carbon_kg is None:
        try:
            total_carbon_kg = float(sum(carbon_data.values())) if carbon_data else 0.0
        except Exception:
            total_carbon_kg = 0.0
    else:
        try:
            total_carbon_kg = float(total_carbon_kg)
        except Exception:
            total_carbon_kg = 0.0

    category_summary = (
        "\n".join([f"- {k}: {float(v):.2f} kg CO2e" for k, v in carbon_data.items()])
        if carbon_data else "- ìƒì„¸ ë°ì´í„° ì—†ìŒ"
    )

    data_summary = (
        "## [ì‚¬ìš©ì ì˜¤ëŠ˜ í•˜ë£¨ íƒ„ì†Œ ë°ì´í„°]\n"
        f"- ì´ ë°°ì¶œëŸ‰: {total_carbon_kg:.2f} kg CO2e\n"
        "## [ì¹´í…Œê³ ë¦¬ë³„ ë°°ì¶œëŸ‰]\n"
        f"{category_summary}\n"
    )

    system_instruction = knowledge_rule["system_instruction"]
    coaching_principles = "\n\n".join(
        [f"- {p}" for p in knowledge_rule.get("coaching_principles", [])]
    )
    json_schema = json.dumps(
        knowledge_rule["json_schema"],
        ensure_ascii=False,
        indent=2,
    )

    # ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""
{system_instruction}

[ë°ì´í„° ë¶„ì„ ì›ì¹™]
{coaching_principles}

[ì‚¬ìš©ì ì…ë ¥ ë°ì´í„°]
{data_summary}

[ì¶œë ¥ í˜•ì‹]
ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¥´ëŠ” **í•˜ë‚˜ì˜ JSON ê°ì²´ë§Œ** ì¶œë ¥í•˜ì„¸ìš”.
ì„¤ëª…ë¬¸Â·ì½”ë“œë¸”ë¡(```) ê¸ˆì§€.

JSON ìŠ¤í‚¤ë§ˆ:
{json_schema}

[ì¶”ê°€ ì¡°ê±´]
- í•œêµ­ì–´ë¡œ ì‘ì„±.
- ì˜¤ëŠ˜ í•˜ë£¨ ë°ì´í„°ë§Œ ê¸°ì¤€.
- í–‰ë™ ì¶”ì²œ 3~5ê°œ í¬í•¨.
- ì •ì±…/í˜œíƒ ì¶”ì²œì€ 1~2ê°œ(ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´).
"""

    return prompt.strip()
